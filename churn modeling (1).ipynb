{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_csv('https://s3.amazonaws.com/hackerday.datascience/104/Telecom_Train.csv')\n",
    "X_train = dataset.iloc[:, 5:-1].values\n",
    "y_train = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_train = LabelEncoder()\n",
    "X_train[:, 0] = labelencoder_X_train.fit_transform(X_train[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X_train = onehotencoder.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the Dependent Variable\n",
    "labelencoder_y_train = LabelEncoder()\n",
    "y_train = labelencoder_y_train.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to avoid the dummy trap on the train set\n",
    "X_train = X_train[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the test dataset\n",
    "dataset_test = pd.read_csv('https://s3.amazonaws.com/hackerday.datascience/104/Telecom_Test.csv')\n",
    "X_test = dataset_test.iloc[:, 5:-1].values\n",
    "y_test = dataset_test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encoding categorical data in the test set\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_test = LabelEncoder()\n",
    "X_test[:, 0] = labelencoder_X_test.fit_transform(X_test[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X_test = onehotencoder.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelencoder_y_test = LabelEncoder()\n",
    "y_test = labelencoder_y_test.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoiding the dummy trap on the test set\n",
    "X_test = X_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85988563413713115"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation for logestic regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0061663984177525548"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting XGBoost to the Training set\n",
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85988563413713115"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation for logestic regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean() \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0061663984177525548"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=0,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting Decision Tree Classification to the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fitting Random Forest Classification to the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82958047868227514"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation for random forest regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011940217983986362"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85358921796047549"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011940217983986362"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83588498678319034"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation for KNN regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83588498678319034"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.333000e+03</td>\n",
       "      <td>3.333000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.687153e-17</td>\n",
       "      <td>1.148779e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.288920e-01</td>\n",
       "      <td>2.004035e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-4.195224e-01</td>\n",
       "      <td>-5.553034e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.780515e-01</td>\n",
       "      <td>-1.461684e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-6.130262e-02</td>\n",
       "      <td>-1.907551e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.502851e-01</td>\n",
       "      <td>1.422231e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.488920e-01</td>\n",
       "      <td>5.500997e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1\n",
       "count  3.333000e+03  3.333000e+03\n",
       "mean  -1.687153e-17  1.148779e-17\n",
       "std    2.288920e-01  2.004035e-01\n",
       "min   -4.195224e-01 -5.553034e-01\n",
       "25%   -1.780515e-01 -1.461684e-01\n",
       "50%   -6.130262e-02 -1.907551e-03\n",
       "75%    2.502851e-01  1.422231e-01\n",
       "max    5.488920e-01  5.500997e-01"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3333.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.144914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  3333.000000\n",
       "mean      0.144914\n",
       "std       0.352067\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "classifier = AdaBoostClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#predicting the test results\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82958047868227514"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011940217983986362"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85358921796047549"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying k-Fold Cross Validation for AdaBoost regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85358921796047549"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83588498678319034"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0099219767408196147"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85268831705957449"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "accuracies.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0040070255471423141"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'loss': ['exponential', 'deviance'], 'learning_rate': [0.05,0.1, 0.01,]}]\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.01, loss='exponential', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_csv('https://s3.amazonaws.com/hackerday.datascience/104/Telecom_Train.csv')\n",
    "X_train = dataset.iloc[:, 5:-1].values\n",
    "y_train = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_train = LabelEncoder()\n",
    "X_train[:, 0] = labelencoder_X_train.fit_transform(X_train[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X_train = onehotencoder.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelencoder_y_train = LabelEncoder()\n",
    "y_train = labelencoder_y_train.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_test = pd.read_csv('https://s3.amazonaws.com/hackerday.datascience/104/Telecom_Test.csv')\n",
    "X_test = dataset_test.iloc[:, 5:-1].values\n",
    "y_test = dataset_test.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_test = LabelEncoder()\n",
    "X_test[:, 0] = labelencoder_X_test.fit_transform(X_test[:, 0])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [0])\n",
    "X_test = onehotencoder.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labelencoder_y_test = LabelEncoder()\n",
    "y_test = labelencoder_y_test.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=15, activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Adding the first hidden layer\n",
    "classifier.add(Dense(output_dim = 8, init = 'uniform', activation = 'relu', input_dim = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"relu\", units=8)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 8, init = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(kernel_initializer=\"uniform\", activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josie\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\keras\\models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.5113 - acc: 0.8539     - ETA: 0s - loss: 0.5969 - acc: 0.\n",
      "Epoch 2/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3637 - acc: 0.8551     \n",
      "Epoch 3/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3599 - acc: 0.8551     \n",
      "Epoch 4/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3580 - acc: 0.8551     \n",
      "Epoch 5/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3560 - acc: 0.8551     \n",
      "Epoch 6/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3539 - acc: 0.8551     \n",
      "Epoch 7/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3528 - acc: 0.8551     \n",
      "Epoch 8/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3513 - acc: 0.8551     \n",
      "Epoch 9/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3506 - acc: 0.8626     \n",
      "Epoch 10/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3497 - acc: 0.8629     \n",
      "Epoch 11/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3477 - acc: 0.8632     \n",
      "Epoch 12/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3471 - acc: 0.8653     \n",
      "Epoch 13/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3463 - acc: 0.8662     \n",
      "Epoch 14/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3443 - acc: 0.8680     \n",
      "Epoch 15/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3429 - acc: 0.8740     \n",
      "Epoch 16/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3391 - acc: 0.8782     \n",
      "Epoch 17/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3343 - acc: 0.8818     \n",
      "Epoch 18/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3263 - acc: 0.8878     \n",
      "Epoch 19/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.3128 - acc: 0.8983     \n",
      "Epoch 20/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2976 - acc: 0.9013     \n",
      "Epoch 21/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2846 - acc: 0.9040     \n",
      "Epoch 22/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2745 - acc: 0.9061     \n",
      "Epoch 23/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2667 - acc: 0.9097     \n",
      "Epoch 24/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2630 - acc: 0.9160     \n",
      "Epoch 25/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2592 - acc: 0.9193     \n",
      "Epoch 26/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2564 - acc: 0.9193     \n",
      "Epoch 27/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2543 - acc: 0.9229     \n",
      "Epoch 28/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2523 - acc: 0.9208     \n",
      "Epoch 29/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2507 - acc: 0.9202     \n",
      "Epoch 30/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2479 - acc: 0.9235     \n",
      "Epoch 31/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2468 - acc: 0.9256     \n",
      "Epoch 32/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2445 - acc: 0.9271     \n",
      "Epoch 33/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2432 - acc: 0.9274     \n",
      "Epoch 34/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2425 - acc: 0.9274     - ETA: 0s - loss: 0.2507 - acc: 0.92\n",
      "Epoch 35/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2402 - acc: 0.9286     - ETA: 0s - loss: 0.2354 - acc: 0.930\n",
      "Epoch 36/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2389 - acc: 0.9286     - ETA: 0s - loss: 0.2543 - acc: 0.\n",
      "Epoch 37/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2388 - acc: 0.9268     \n",
      "Epoch 38/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2370 - acc: 0.9289     \n",
      "Epoch 39/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2359 - acc: 0.9301     \n",
      "Epoch 40/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2362 - acc: 0.9289     \n",
      "Epoch 41/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2341 - acc: 0.9298     \n",
      "Epoch 42/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2333 - acc: 0.9307     \n",
      "Epoch 43/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2329 - acc: 0.9307     \n",
      "Epoch 44/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2313 - acc: 0.9307     \n",
      "Epoch 45/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2313 - acc: 0.9307     \n",
      "Epoch 46/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2310 - acc: 0.9304     \n",
      "Epoch 47/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2299 - acc: 0.9319     \n",
      "Epoch 48/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2290 - acc: 0.9328     \n",
      "Epoch 49/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2286 - acc: 0.9307     \n",
      "Epoch 50/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2279 - acc: 0.9313     \n",
      "Epoch 51/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2273 - acc: 0.9331     \n",
      "Epoch 52/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2267 - acc: 0.9328     \n",
      "Epoch 53/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2248 - acc: 0.9325     \n",
      "Epoch 54/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2241 - acc: 0.9331     \n",
      "Epoch 55/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2237 - acc: 0.9334     \n",
      "Epoch 56/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2225 - acc: 0.9328     \n",
      "Epoch 57/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2219 - acc: 0.9325     \n",
      "Epoch 58/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2209 - acc: 0.9343     \n",
      "Epoch 59/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2211 - acc: 0.9322     \n",
      "Epoch 60/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2195 - acc: 0.9343     \n",
      "Epoch 61/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2203 - acc: 0.9334     \n",
      "Epoch 62/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2185 - acc: 0.9358     \n",
      "Epoch 63/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2189 - acc: 0.9346     \n",
      "Epoch 64/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2164 - acc: 0.9337     \n",
      "Epoch 65/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2172 - acc: 0.9349     \n",
      "Epoch 66/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2167 - acc: 0.9361     \n",
      "Epoch 67/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2158 - acc: 0.9370     \n",
      "Epoch 68/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2160 - acc: 0.9361     \n",
      "Epoch 69/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2161 - acc: 0.9352     \n",
      "Epoch 70/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2145 - acc: 0.9367     \n",
      "Epoch 71/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2143 - acc: 0.9367     \n",
      "Epoch 72/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2139 - acc: 0.9355     \n",
      "Epoch 73/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2135 - acc: 0.9352     \n",
      "Epoch 74/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2132 - acc: 0.9346     \n",
      "Epoch 75/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2120 - acc: 0.9364     \n",
      "Epoch 76/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2132 - acc: 0.9376     \n",
      "Epoch 77/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2109 - acc: 0.9388     \n",
      "Epoch 78/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2118 - acc: 0.9385     \n",
      "Epoch 79/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2115 - acc: 0.9379     \n",
      "Epoch 80/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2111 - acc: 0.9364     \n",
      "Epoch 81/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2114 - acc: 0.9361     - ETA: 0s - loss: 0.2076 - acc: 0.93\n",
      "Epoch 82/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2113 - acc: 0.9379     \n",
      "Epoch 83/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2107 - acc: 0.9376     \n",
      "Epoch 84/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2095 - acc: 0.9394     \n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3333/3333 [==============================] - 0s - loss: 0.2092 - acc: 0.9373     \n",
      "Epoch 86/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2100 - acc: 0.9382     \n",
      "Epoch 87/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2092 - acc: 0.9388     - ETA: 0s - loss: 0.1777 - acc: 0.948 - ETA: 0s - loss: 0.1909 - ac\n",
      "Epoch 88/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2088 - acc: 0.9397     \n",
      "Epoch 89/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2080 - acc: 0.9391     \n",
      "Epoch 90/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2073 - acc: 0.9403     \n",
      "Epoch 91/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2077 - acc: 0.9397     - ETA: 0s - loss: 0.2251 - acc: 0.9\n",
      "Epoch 92/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2069 - acc: 0.9382     \n",
      "Epoch 93/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2068 - acc: 0.9388     \n",
      "Epoch 94/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2061 - acc: 0.9391     \n",
      "Epoch 95/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2051 - acc: 0.9403     \n",
      "Epoch 96/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2061 - acc: 0.9394     \n",
      "Epoch 97/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2050 - acc: 0.9397     \n",
      "Epoch 98/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2057 - acc: 0.9391     \n",
      "Epoch 99/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2049 - acc: 0.9409     \n",
      "Epoch 100/100\n",
      "3333/3333 [==============================] - 0s - loss: 0.2049 - acc: 0.9397     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179ab77fef0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85268831705957449"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0040070255471423141"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
    "mean = accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tuning the ANN using grid search\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 15))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
